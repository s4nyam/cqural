

![image](https://user-images.githubusercontent.com/13884479/224863746-dd90b2a9-26f9-470b-9b8c-cb65f9e13deb.png)
Abstractâ€”Training machine learning models in an incremental fashion is not only important but also an efficient way to achieve artificial general intelligence. The ability that humans possess of continuous or lifelong learning helps them to not forget previously learned tasks. However, current neural network models are prone to catastrophic forgetting when it comes to continual learning. Many researchers have come up with several techniques in order to reduce the effect of forgetting from neural networks, however, all techniques are studied classically with a very less focus on changing the machine learning model architecture. In this research paper, we show that it is not only possible to circumvent catastrophic forgetting in continual learning with novel hybrid classical-quantum neural networks, but also ex- plains what features are most important to learn for classification. In addition, we also claim that if the model is trained with these explanations, it tends to give better performance and learn specific features that are far from the decision boundary. Finally, we present the experimental results to show comparisons between classical and classical-quantum hybrid architectures on benchmark MNIST and CIFAR-10 datasets. After successful runs of learning procedure, we found hybrid neural network outperforms classical one in terms of remembering the right evidences of the class-specific features.


<img width="425" alt="Screenshot 2023-03-14 at 1 48 09 AM" src="https://user-images.githubusercontent.com/13884479/224863973-d3008b63-8dd8-424d-a294-16bb3fce33c4.png">


<img width="451" alt="Screenshot 2023-03-14 at 1 48 44 AM" src="https://user-images.githubusercontent.com/13884479/224864039-ccbbba7e-e84c-4b80-95fa-884feb98cec8.png">


<img width="463" alt="Screenshot 2023-03-14 at 1 48 54 AM" src="https://user-images.githubusercontent.com/13884479/224864057-3f8cfade-42f0-426f-9ed3-7cde7c05402e.png">


<img width="486" alt="Screenshot 2023-03-14 at 1 49 05 AM" src="https://user-images.githubusercontent.com/13884479/224864086-aca6e3e7-1e20-44d0-9a38-059b6f24d43b.png">


<img width="481" alt="Screenshot 2023-03-14 at 1 49 17 AM" src="https://user-images.githubusercontent.com/13884479/224864106-f57259bc-5d4d-42c0-bec4-ebc83c663f94.png">


<img width="491" alt="Screenshot 2023-03-14 at 1 49 25 AM" src="https://user-images.githubusercontent.com/13884479/224864124-008aef82-9be0-4dc1-b73f-08161052e21e.png">


<img width="478" alt="Screenshot 2023-03-14 at 1 49 36 AM" src="https://user-images.githubusercontent.com/13884479/224864145-b1584533-391b-4bcc-a76a-b63273d24cca.png">


<img width="483" alt="Screenshot 2023-03-14 at 1 49 45 AM" src="https://user-images.githubusercontent.com/13884479/224864171-71095f78-324b-42da-b5b2-ecbe9ac3f608.png">


<img width="484" alt="Screenshot 2023-03-14 at 1 49 59 AM" src="https://user-images.githubusercontent.com/13884479/224864196-7549f905-8cf2-4c83-b2b0-9f8925355072.png">

